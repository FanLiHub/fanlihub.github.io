---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Hi there, I am Fan Li (æå¸†), a Ph.D. candidate at the School of Artificial Intelligence (formerly the Unmanned Systems Technology Research Institute), Northwestern Polytechnical University (NPU). My research lies at the intersection of computer vision and autonomous unmanned systems, with a focus on robust scene understanding under complex and shifting visual domains. Specifically, my research interests include:

- Generative-driven next-generation perception models

- Generalization of unmanned systems in complex and dynamic environments

- Robust visual understanding in open-world scenarios

- Multi-modal dynamic scene understanding


My research aims to enable robust and reliable visual perception and scene understanding for unmanned systems operating in complex and dynamic environments. This work serves to

I am always open to collaboration and interdisciplinary conversation.
You can explore my publications on Google Scholar or contact me at lifan.messages@gmail.com.


# ğŸ”¥ News
- *2025.09*: &nbsp;ğŸ‰ A paper on 3D semantic segmentation was accepted to **NeurIPS 2025 Main Track**.
- *2025.06*: &nbsp;ğŸ‰ A paper on open-world semantic segmentation was accepted to **ICCV 2025** and was awarded as a **Highlight**.
- *2025.05*: &nbsp;ğŸ‰ A paper on domain generalization was accepted to **ICML 2025** and was awarded as a **Spotlight**.
- *2025.03*: &nbsp;ğŸ‰ A paper on domain adaptation was accepted to ICME 2025.

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICML 2025</div><img src='images/ICML2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Better to Teach than to Give: Domain Generalized Semantic Segmentation via Agent Queries with Diffusion Model Guidance](https://proceedings.mlr.press/v267/li25co.html)

**Fan Li**, Xuan Wang, Min Qi, Zhaoxiang Zhang, Yuelei Xu

Accepted at **ICML 2025** (**Spotlight**ğŸ’¡)

[**Project**](https://github.com/FanLiHub/QueryDiff) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Developed an agent-queryâ€“driven framework for domain-generalized semantic segmentation, in which learnable agent queries act as an interface to inject diffusion-model priors into visual perception networks, thereby improving cross-domain generalization.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2025</div><img src='images/ICCV2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Images as Noisy Labels: Unleashing the Potential of the Diffusion Model for Open-Vocabulary Semantic Segmentation](https://openaccess.thecvf.com/content/ICCV2025/html/Li_Images_as_Noisy_Labels_Unleashing_the_Potential_of_the_Diffusion_ICCV_2025_paper.html)

**Fan Li**, Xuanbin Wang, Xuan Wang, Zhaoxiang Zhang, Yuelei Xu

Accepted at **ICCV 2025** (**Highlight**ğŸ’¡)

[**Project**](https://github.com/FanLiHub/DEDOS) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Developed the first denoising-based learning framework for visual perception, which treats images as noisy labels and acquires semantic knowledge during the iterative denoising process of diffusion models, thereby enhancing fine-grained scene understanding in open-world scenarios for visionâ€“language models.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2025</div><img src='images/NeurIPS2025.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

No Object Is an Island: Enhancing 3D Semantic Segmentation Generalization with Diffusion Models

**Fan Li**, Xuan Wang, Xuanbin Wang, Zhaoxiang Zhang, Yuelei Xu

Accepted at **NeurIPS 2025 Main Track**

[**Project**]([https://github.com/FanLiHub/DEDOS](https://github.com/FanLiHub/XDiff3D)) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Developed the first diffusion-based cross-domain 3D semantic segmentation framework, leveraging pretrained 2D image diffusion priors to guide 3D models in establishing semantic dependencies among point-cloud instances, thereby enabling cross-modal semantic enhancement and enriching point-cloud representations.
</div>
</div>


- Unlocking Instance Semantic Awareness for Domain Adaptive Semantic Segmentation. **Fan Li**, Xuan Wang, Min Qi, Zhaoxiang Zhang, Chengming Xu, Yuelei Xu. **ICME 2025**

# ğŸ– Honors and Awards
- *2023.04*: ğŸ† National Silver Award, The 8th China International College Studentsâ€™ â€œInternet+â€ Innovation and Entrepreneurship Competition 
- *2022.08*: ğŸ† Gold Award (Ã—2), The 8th China International â€œInternet+â€ Innovation and Entrepreneurship Competition (Shaanxi Provincial Level)
- *2022.07*: ğŸ† First Prize, 17th China Graduate Electronics Design Competition â€“ Special Track (Preliminary Round)
- *2023.10*: ğŸ† Outstanding Graduate Student, Northwestern Polytechnical University

# ğŸ“– Educations
- *2020.09 â€“ Present*, Ph.D. Program in Intelligent Unmanned Systems Science and Technology,
School of Artificial Intelligence (formerly Institute of Unmanned Systems Technology),
Northwestern Polytechnical University
- *2016.09 â€“ 2020.06*, B.E. in Computer Science and Technology,
China University of Geosciences

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
